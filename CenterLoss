Centerloss的应用

centerloss在人脸识别的效果显著，但是我在训练的时候发现，先训练一个不带centerloss的人脸模型，之后基于这个pretrain model加入centerloss进行微调效果更佳好一点。

centerloss对于output number比较高的任务有较高的表现力。例如一般来说人脸识别的分类的output number=10000+，因此提高类内距是有必要的。但是在output number较低的任务中，例如cifar10/cifar100，表现力可能会下降。


Center Loss损失函数

以mnist数据集为例.(手写数字,28*28图像,10分类问题)
categorical crossentropy(softmax loss)的问题

通常会使用softmax loss多分类损失函数.
缺点:
    从聚类角度看,提取的特征并不好.很多情况下类内间距甚至要大于类间间距.我们期望特征不仅可分，而且要求差异大，特征学习需要保证提取的特征有识别度。占据的面积有点大.通常情况下,我们希望每一类只占很小一部分.因为手写字符很多啊,这些数字就占了这么大地方,如果新来了英文字母呢…也就是我们期望模型能识别出在训练数据的标签中没有的分类。特征学习需要保证提取的特征具有普适性. softmax会使得模型过度自信,分类结果基本非1即0,上图里有些点在边界但是softmax认为已经可以了,根本没必要再修正.同时softmax这种特性使得基本上没有办法去设置诸如可信度度量

原因?举例:
最后一层全连接层输出V=[x1,x2,x3],真实标签是[1,0,0].那么假设V=[x1,x2,x3]是[3.1,3,3],那么softmax的公式使得其只需要V的模长增加倍数即可以降低loss损失.这太容易(只需要增大参数即可)使得网络往往就是这样做的.而不是我们通常想要的那样去努力降低x2,x3的相对于x1的值如[3.1,1,1]这样.

Center Loss

针对softmax表现出的问题针对性解决 →类内间距太大了.

    对每一个类都维护一个类中心c,而后在特征层如果该样本里类中心的特征太远就要惩罚.也就是所谓的centerloss.

    类中心c:每一个样本的特征需要通过一个好的网络到达特征层获得,这样计算完后所有样本的特征的平均值为类中心c,而好的网络需要是在有类中心加入的情况下才能得到…

    没法直接获得c,所以将其放到网络里自己生成,在每一个batch里更新center.即随机初始化center,而后每一个batch里计算当前数据与center的距离,而后将这个梯度形式的距离加到center上.类似于参数修正.同样的类似于梯度下降法,这里再增加一个scale度量a,使得center不会抖动.

    实验表明只使用centerloss效果很一般,所以一般是将centerloss与softmax结合起来,引入参数lambda.

5.实验结果

准确度提高约0.6%.
总结

    一种新的loss函数,看起来效果不错,而且也更加符合认知,生成的模型鲁棒性可能更好. 本质是度量学习,经常应用在分类领域,原理简单,计算复杂度不大,经常能提升效果. 有点使用空间换取时间的意思. 属于一个trick.不一定适合所有场景.一般来说,如果同一类样本很类似如mnist手写数字,人脸数据,那么centerloss往往能够带来效果提升.而如果本身同一类样本就差异很大,如cifar100,那么则不一定.也可以理解成一个人的一堆脸取平均值仍然是他的脸,而一堆不同的狗取平均值则可能难以认出是什么. 参数设置:a一般取0.5,lambda则0.1-0.0001之间不等,需要实验调参.
